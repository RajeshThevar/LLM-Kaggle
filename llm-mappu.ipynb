{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-22T11:08:16.850422Z","iopub.execute_input":"2023-08-22T11:08:16.851254Z","iopub.status.idle":"2023-08-22T11:08:17.405505Z","shell.execute_reply.started":"2023-08-22T11:08:16.851217Z","shell.execute_reply":"2023-08-22T11:08:17.404481Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/additional-train-data-for-llm-science-exam/6000_train_examples.csv\n/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv\n/kaggle/input/dolly-v2-7b-8bit/config.json\n/kaggle/input/dolly-v2-7b-8bit/tokenizer.json\n/kaggle/input/dolly-v2-7b-8bit/tokenizer_config.json\n/kaggle/input/dolly-v2-7b-8bit/pytorch_model.bin\n/kaggle/input/dolly-v2-7b-8bit/special_tokens_map.json\n/kaggle/input/dolly-v2-7b-8bit/generation_config.json\n/kaggle/input/kaggle-llm-science-exam/sample_submission.csv\n/kaggle/input/kaggle-llm-science-exam/train.csv\n/kaggle/input/kaggle-llm-science-exam/test.csv\n/kaggle/input/falcon-7b-8bit/config.json\n/kaggle/input/falcon-7b-8bit/configuration_falcon.py\n/kaggle/input/falcon-7b-8bit/configuration_RW.py\n/kaggle/input/falcon-7b-8bit/README.md\n/kaggle/input/falcon-7b-8bit/tokenizer.json\n/kaggle/input/falcon-7b-8bit/tokenizer_config.json\n/kaggle/input/falcon-7b-8bit/modeling_falcon.py\n/kaggle/input/falcon-7b-8bit/pytorch_model.bin.index.json\n/kaggle/input/falcon-7b-8bit/pytorch_model.bin\n/kaggle/input/falcon-7b-8bit/special_tokens_map.json\n/kaggle/input/falcon-7b-8bit/generation_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:21.629406Z","iopub.execute_input":"2023-08-22T11:09:21.629781Z","iopub.status.idle":"2023-08-22T11:09:32.059397Z","shell.execute_reply.started":"2023-08-22T11:09:21.629749Z","shell.execute_reply":"2023-08-22T11:09:32.058392Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cloud AutoML\nfrom google.cloud import automl_v1beta1 as automl\nautoml_client = automl.AutoMlClient()\n\n# Cloud Translation\nfrom google.cloud import translate_v2\ntranslate_client = translate_v2.Client()\n\n# Cloud Natural Language\nfrom google.cloud import language_v1\nclient = language_v1.LanguageServiceClient()\n\n# Cloud Video Intelligence\nfrom google.cloud import videointelligence\nvideo_client = videointelligence.VideoIntelligenceServiceClient()\n\n# Cloud Vision\nfrom google.cloud import vision\nclient = vision.ImageAnnotatorClient()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:37.299339Z","iopub.execute_input":"2023-08-22T11:09:37.300038Z","iopub.status.idle":"2023-08-22T11:09:37.309721Z","shell.execute_reply.started":"2023-08-22T11:09:37.300004Z","shell.execute_reply":"2023-08-22T11:09:37.308539Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\"\"\" \nCredits\nTakamichi Toda. 8-bit quantized LLM models: https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/424334#2343740\nSFT: https://huggingface.co/docs/trl/main/en/sft_trainer\nPerplexity: # https://www.kaggle.com/code/philippsinger/h2ogpt-perplexity-ranking/notebook\n\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:38.242483Z","iopub.execute_input":"2023-08-22T11:09:38.242870Z","iopub.status.idle":"2023-08-22T11:09:38.250228Z","shell.execute_reply.started":"2023-08-22T11:09:38.242838Z","shell.execute_reply":"2023-08-22T11:09:38.249261Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"' \\nCredits\\nTakamichi Toda. 8-bit quantized LLM models: https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/424334#2343740\\nSFT: https://huggingface.co/docs/trl/main/en/sft_trainer\\nPerplexity: # https://www.kaggle.com/code/philippsinger/h2ogpt-perplexity-ranking/notebook\\n\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install -q datasets transformers wandb sentencepiece accelerate","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:42.340736Z","iopub.execute_input":"2023-08-22T11:09:42.341086Z","iopub.status.idle":"2023-08-22T11:09:54.604116Z","shell.execute_reply.started":"2023-08-22T11:09:42.341055Z","shell.execute_reply":"2023-08-22T11:09:54.602794Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntrainExtra_df = pd.read_csv('/kaggle/input/additional-train-data-for-llm-science-exam/6000_train_examples.csv')\nmainTrain_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\nprint(trainExtra_df.shape, mainTrain_df.shape)\nmainTrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:54.606796Z","iopub.execute_input":"2023-08-22T11:09:54.607195Z","iopub.status.idle":"2023-08-22T11:09:54.736667Z","shell.execute_reply.started":"2023-08-22T11:09:54.607153Z","shell.execute_reply":"2023-08-22T11:09:54.735634Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(6000, 7) (200, 8)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   id                                             prompt  \\\n0   0  Which of the following statements accurately d...   \n1   1  Which of the following is an accurate definiti...   \n2   2  Which of the following statements accurately d...   \n3   3  What is the significance of regularization in ...   \n4   4  Which of the following statements accurately d...   \n\n                                                   A  \\\n0  MOND is a theory that reduces the observed mis...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol was reconstructed as a fe...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   B  \\\n0  MOND is a theory that increases the discrepanc...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol is a representation of th...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   C  \\\n0  MOND is a theory that explains the missing bar...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol is a representation of a ...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   D  \\\n0  MOND is a theory that reduces the discrepancy ...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol represents three interloc...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   E answer  \n0  MOND is a theory that eliminates the observed ...      D  \n1  Dynamic scaling refers to the evolution of sel...      A  \n2  The triskeles symbol is a representation of th...      A  \n3  Regularizing the mass-energy of an electron wi...      C  \n4  The angular spacing of features in the diffrac...      D  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>D</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:54.738152Z","iopub.execute_input":"2023-08-22T11:09:54.738578Z","iopub.status.idle":"2023-08-22T11:09:54.743642Z","shell.execute_reply.started":"2023-08-22T11:09:54.738544Z","shell.execute_reply":"2023-08-22T11:09:54.742658Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"iskaggle","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:54.746778Z","iopub.execute_input":"2023-08-22T11:09:54.748090Z","iopub.status.idle":"2023-08-22T11:09:54.754914Z","shell.execute_reply.started":"2023-08-22T11:09:54.748053Z","shell.execute_reply":"2023-08-22T11:09:54.753890Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'Interactive'"},"metadata":{}}]},{"cell_type":"code","source":"!mkdir ~/.kaggle\n!touch ~/.kaggle/kaggle.json\n\napi_token = {\"username\":\"rajeshthevar\",\"key\":\"ce00ae1ec01c54a33ad91cb57c09a25e\"}\n\nimport json\n\nwith open('/root/.kaggle/kaggle.json', 'w') as file:\n    json.dump(api_token, file)\n\n!chmod 600 ~/.kaggle/kaggle.json","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:54.756241Z","iopub.execute_input":"2023-08-22T11:09:54.757331Z","iopub.status.idle":"2023-08-22T11:09:57.700240Z","shell.execute_reply.started":"2023-08-22T11:09:54.757293Z","shell.execute_reply":"2023-08-22T11:09:57.698938Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!mkdir -p ./kaggle/input/einops ./kaggle/input/bitsandbytes ./kaggle/input/peft ./kaggle/input/accelerate ./kaggle/input/trl","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:57.702210Z","iopub.execute_input":"2023-08-22T11:09:57.702594Z","iopub.status.idle":"2023-08-22T11:09:58.674114Z","shell.execute_reply.started":"2023-08-22T11:09:57.702560Z","shell.execute_reply":"2023-08-22T11:09:58.672787Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!ls -d ./kaggle/input/*","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:58.675912Z","iopub.execute_input":"2023-08-22T11:09:58.676625Z","iopub.status.idle":"2023-08-22T11:09:59.657647Z","shell.execute_reply.started":"2023-08-22T11:09:58.676583Z","shell.execute_reply":"2023-08-22T11:09:59.656450Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"./kaggle/input/accelerate    ./kaggle/input/einops  ./kaggle/input/trl\n./kaggle/input/bitsandbytes  ./kaggle/input/peft\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip download einops -d ./kaggle/input/einops\n!pip download bitsandbytes -d ./kaggle/input/bitsandbytes\n!pip download peft -d ./kaggle/input/peft\n!pip download accelerate -d ./kaggle/input/accelerate\n!pip download trl -d ./kaggle/input/trl","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:09:59.659885Z","iopub.execute_input":"2023-08-22T11:09:59.660789Z","iopub.status.idle":"2023-08-22T11:14:31.095812Z","shell.execute_reply.started":"2023-08-22T11:09:59.660744Z","shell.execute_reply":"2023-08-22T11:14:31.094517Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Collecting einops\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hSaved ./kaggle/input/einops/einops-0.6.1-py3-none-any.whl\nSuccessfully downloaded einops\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hSaved ./kaggle/input/bitsandbytes/bitsandbytes-0.41.1-py3-none-any.whl\nSuccessfully downloaded bitsandbytes\nCollecting peft\n  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting numpy>=1.17 (from peft)\n  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting packaging>=20.0 (from peft)\n  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting psutil (from peft)\n  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.1/282.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyyaml (from peft)\n  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torch>=1.13.0 (from peft)\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting transformers (from peft)\n  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tqdm (from peft)\n  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate (from peft)\n  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting safetensors (from peft)\n  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting filelock (from torch>=1.13.0->peft)\n  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\nCollecting typing-extensions (from torch>=1.13.0->peft)\n  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nCollecting sympy (from torch>=1.13.0->peft)\n  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting networkx (from torch>=1.13.0->peft)\n  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jinja2 (from torch>=1.13.0->peft)\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.13.0->peft)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.13.0->peft)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.13.0->peft)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.13.0->peft)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.13.0->peft)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.13.0->peft)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.13.0->peft)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.13.0->peft)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.13.0->peft)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.13.0->peft)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.13.0->peft)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==2.0.0 (from torch>=1.13.0->peft)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting setuptools (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft)\n  Downloading setuptools-68.1.2-py3-none-any.whl (805 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.1/805.1 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft)\n  Downloading wheel-0.41.2-py3-none-any.whl (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting cmake (from triton==2.0.0->torch>=1.13.0->peft)\n  Downloading cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting lit (from triton==2.0.0->torch>=1.13.0->peft)\n  Downloading lit-16.0.6.tar.gz (153 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.7/153.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting huggingface-hub<1.0,>=0.14.1 (from transformers->peft)\n  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting regex!=2019.12.17 (from transformers->peft)\n  Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting requests (from transformers->peft)\n  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->peft)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting fsspec (from huggingface-hub<1.0,>=0.14.1->transformers->peft)\n  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch>=1.13.0->peft)\n  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nCollecting charset-normalizer<4,>=2 (from requests->transformers->peft)\n  Downloading charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (201 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting idna<4,>=2.5 (from requests->transformers->peft)\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests->transformers->peft)\n  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting certifi>=2017.4.17 (from requests->transformers->peft)\n  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting mpmath>=0.19 (from sympy->torch>=1.13.0->peft)\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hSaved ./kaggle/input/peft/peft-0.5.0-py3-none-any.whl\nSaved ./kaggle/input/peft/numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/peft/packaging-23.1-py3-none-any.whl\nSaved ./kaggle/input/peft/torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/peft/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\nSaved ./kaggle/input/peft/accelerate-0.21.0-py3-none-any.whl\nSaved ./kaggle/input/peft/psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/peft/PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/peft/safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/peft/tqdm-4.66.1-py3-none-any.whl\nSaved ./kaggle/input/peft/transformers-4.31.0-py3-none-any.whl\nSaved ./kaggle/input/peft/huggingface_hub-0.16.4-py3-none-any.whl\nSaved ./kaggle/input/peft/regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/peft/tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/peft/typing_extensions-4.7.1-py3-none-any.whl\nSaved ./kaggle/input/peft/filelock-3.12.2-py3-none-any.whl\nSaved ./kaggle/input/peft/Jinja2-3.1.2-py3-none-any.whl\nSaved ./kaggle/input/peft/networkx-3.1-py3-none-any.whl\nSaved ./kaggle/input/peft/requests-2.31.0-py3-none-any.whl\nSaved ./kaggle/input/peft/sympy-1.12-py3-none-any.whl\nSaved ./kaggle/input/peft/certifi-2023.7.22-py3-none-any.whl\nSaved ./kaggle/input/peft/charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/peft/idna-3.4-py3-none-any.whl\nSaved ./kaggle/input/peft/MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/peft/mpmath-1.3.0-py3-none-any.whl\nSaved ./kaggle/input/peft/urllib3-2.0.4-py3-none-any.whl\nSaved ./kaggle/input/peft/cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\nSaved ./kaggle/input/peft/fsspec-2023.6.0-py3-none-any.whl\nSaved ./kaggle/input/peft/lit-16.0.6.tar.gz\nSaved ./kaggle/input/peft/setuptools-68.1.2-py3-none-any.whl\nSaved ./kaggle/input/peft/wheel-0.41.2-py3-none-any.whl\nSuccessfully downloaded peft numpy packaging torch nvidia-cublas-cu11 nvidia-cuda-cupti-cu11 nvidia-cuda-nvrtc-cu11 nvidia-cuda-runtime-cu11 nvidia-cudnn-cu11 nvidia-cufft-cu11 nvidia-curand-cu11 nvidia-cusolver-cu11 nvidia-cusparse-cu11 nvidia-nccl-cu11 nvidia-nvtx-cu11 triton accelerate psutil pyyaml safetensors tqdm transformers huggingface-hub regex tokenizers typing-extensions filelock jinja2 networkx requests sympy certifi charset-normalizer idna MarkupSafe mpmath urllib3 cmake fsspec lit setuptools wheel\nCollecting accelerate\n  Using cached accelerate-0.21.0-py3-none-any.whl (244 kB)\nCollecting numpy>=1.17 (from accelerate)\n  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\nCollecting packaging>=20.0 (from accelerate)\n  Using cached packaging-23.1-py3-none-any.whl (48 kB)\nCollecting psutil (from accelerate)\n  Using cached psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\nCollecting pyyaml (from accelerate)\n  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\nCollecting torch>=1.10.0 (from accelerate)\n  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\nCollecting filelock (from torch>=1.10.0->accelerate)\n  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\nCollecting typing-extensions (from torch>=1.10.0->accelerate)\n  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nCollecting sympy (from torch>=1.10.0->accelerate)\n  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\nCollecting networkx (from torch>=1.10.0->accelerate)\n  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\nCollecting jinja2 (from torch>=1.10.0->accelerate)\n  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\nCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\nCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\nCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\nCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\nCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\nCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.10.0->accelerate)\n  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\nCollecting triton==2.0.0 (from torch>=1.10.0->accelerate)\n  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\nCollecting setuptools (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate)\n  Using cached setuptools-68.1.2-py3-none-any.whl (805 kB)\nCollecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate)\n  Using cached wheel-0.41.2-py3-none-any.whl (64 kB)\nCollecting cmake (from triton==2.0.0->torch>=1.10.0->accelerate)\n  Using cached cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\nCollecting lit (from triton==2.0.0->torch>=1.10.0->accelerate)\n  Using cached lit-16.0.6.tar.gz (153 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch>=1.10.0->accelerate)\n  Using cached MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nCollecting mpmath>=0.19 (from sympy->torch>=1.10.0->accelerate)\n  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\nSaved ./kaggle/input/accelerate/accelerate-0.21.0-py3-none-any.whl\nSaved ./kaggle/input/accelerate/numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/accelerate/packaging-23.1-py3-none-any.whl\nSaved ./kaggle/input/accelerate/torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/accelerate/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\nSaved ./kaggle/input/accelerate/psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/accelerate/PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/accelerate/filelock-3.12.2-py3-none-any.whl\nSaved ./kaggle/input/accelerate/Jinja2-3.1.2-py3-none-any.whl\nSaved ./kaggle/input/accelerate/networkx-3.1-py3-none-any.whl\nSaved ./kaggle/input/accelerate/sympy-1.12-py3-none-any.whl\nSaved ./kaggle/input/accelerate/typing_extensions-4.7.1-py3-none-any.whl\nSaved ./kaggle/input/accelerate/MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/accelerate/mpmath-1.3.0-py3-none-any.whl\nSaved ./kaggle/input/accelerate/cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\nSaved ./kaggle/input/accelerate/lit-16.0.6.tar.gz\nSaved ./kaggle/input/accelerate/setuptools-68.1.2-py3-none-any.whl\nSaved ./kaggle/input/accelerate/wheel-0.41.2-py3-none-any.whl\nSuccessfully downloaded accelerate numpy packaging torch nvidia-cublas-cu11 nvidia-cuda-cupti-cu11 nvidia-cuda-nvrtc-cu11 nvidia-cuda-runtime-cu11 nvidia-cudnn-cu11 nvidia-cufft-cu11 nvidia-curand-cu11 nvidia-cusolver-cu11 nvidia-cusparse-cu11 nvidia-nccl-cu11 nvidia-nvtx-cu11 triton psutil pyyaml filelock jinja2 networkx sympy typing-extensions MarkupSafe mpmath cmake lit setuptools wheel\nCollecting trl\n  Downloading trl-0.5.0-py3-none-any.whl (88 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/88.1 kB\u001b[0m \u001b[31m147.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torch>=1.4.0 (from trl)\n  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\nCollecting transformers>=4.18.0 (from trl)\n  Using cached transformers-4.31.0-py3-none-any.whl (7.4 MB)\nCollecting numpy>=1.18.2 (from trl)\n  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\nCollecting accelerate (from trl)\n  Using cached accelerate-0.21.0-py3-none-any.whl (244 kB)\nCollecting datasets (from trl)\n  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting filelock (from torch>=1.4.0->trl)\n  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\nCollecting typing-extensions (from torch>=1.4.0->trl)\n  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nCollecting sympy (from torch>=1.4.0->trl)\n  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\nCollecting networkx (from torch>=1.4.0->trl)\n  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\nCollecting jinja2 (from torch>=1.4.0->trl)\n  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.4.0->trl)\n  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.4.0->trl)\n  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\nCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.4.0->trl)\n  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.4.0->trl)\n  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.4.0->trl)\n  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.4.0->trl)\n  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\nCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.4.0->trl)\n  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\nCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.4.0->trl)\n  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\nCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.4.0->trl)\n  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\nCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.4.0->trl)\n  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\nCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.4.0->trl)\n  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\nCollecting triton==2.0.0 (from torch>=1.4.0->trl)\n  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\nCollecting setuptools (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->trl)\n  Using cached setuptools-68.1.2-py3-none-any.whl (805 kB)\nCollecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->trl)\n  Using cached wheel-0.41.2-py3-none-any.whl (64 kB)\nCollecting cmake (from triton==2.0.0->torch>=1.4.0->trl)\n  Using cached cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\nCollecting lit (from triton==2.0.0->torch>=1.4.0->trl)\n  Using cached lit-16.0.6.tar.gz (153 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.18.0->trl)\n  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\nCollecting packaging>=20.0 (from transformers>=4.18.0->trl)\n  Using cached packaging-23.1-py3-none-any.whl (48 kB)\nCollecting pyyaml>=5.1 (from transformers>=4.18.0->trl)\n  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\nCollecting regex!=2019.12.17 (from transformers>=4.18.0->trl)\n  Using cached regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\nCollecting requests (from transformers>=4.18.0->trl)\n  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.18.0->trl)\n  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\nCollecting safetensors>=0.3.1 (from transformers>=4.18.0->trl)\n  Using cached safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\nCollecting tqdm>=4.27 (from transformers>=4.18.0->trl)\n  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\nCollecting psutil (from accelerate->trl)\n  Using cached psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\nCollecting pyarrow>=8.0.0 (from datasets->trl)\n  Downloading pyarrow-12.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting dill<0.3.8,>=0.3.0 (from datasets->trl)\n  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pandas (from datasets->trl)\n  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hCollecting xxhash (from datasets->trl)\n  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting multiprocess (from datasets->trl)\n  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fsspec[http]>=2021.11.1 (from datasets->trl)\n  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\nCollecting aiohttp (from datasets->trl)\n  Downloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting attrs>=17.3.0 (from aiohttp->datasets->trl)\n  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting charset-normalizer<4.0,>=2.0 (from aiohttp->datasets->trl)\n  Using cached charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (201 kB)\nCollecting multidict<7.0,>=4.5 (from aiohttp->datasets->trl)\n  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets->trl)\n  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nCollecting yarl<2.0,>=1.0 (from aiohttp->datasets->trl)\n  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets->trl)\n  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets->trl)\n  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\nCollecting idna<4,>=2.5 (from requests->transformers>=4.18.0->trl)\n  Using cached idna-3.4-py3-none-any.whl (61 kB)\nCollecting urllib3<3,>=1.21.1 (from requests->transformers>=4.18.0->trl)\n  Using cached urllib3-2.0.4-py3-none-any.whl (123 kB)\nCollecting certifi>=2017.4.17 (from requests->transformers>=4.18.0->trl)\n  Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\nCollecting MarkupSafe>=2.0 (from jinja2->torch>=1.4.0->trl)\n  Using cached MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nCollecting python-dateutil>=2.8.2 (from pandas->datasets->trl)\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pytz>=2020.1 (from pandas->datasets->trl)\n  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tzdata>=2022.1 (from pandas->datasets->trl)\n  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting mpmath>=0.19 (from sympy->torch>=1.4.0->trl)\n  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\nCollecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets->trl)\n  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nSaved ./kaggle/input/trl/trl-0.5.0-py3-none-any.whl\nSaved ./kaggle/input/trl/numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl\nSaved ./kaggle/input/trl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\nSaved ./kaggle/input/trl/transformers-4.31.0-py3-none-any.whl\nSaved ./kaggle/input/trl/accelerate-0.21.0-py3-none-any.whl\nSaved ./kaggle/input/trl/datasets-2.14.4-py3-none-any.whl\nSaved ./kaggle/input/trl/dill-0.3.7-py3-none-any.whl\nSaved ./kaggle/input/trl/aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/huggingface_hub-0.16.4-py3-none-any.whl\nSaved ./kaggle/input/trl/packaging-23.1-py3-none-any.whl\nSaved ./kaggle/input/trl/pyarrow-12.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/requests-2.31.0-py3-none-any.whl\nSaved ./kaggle/input/trl/safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/tqdm-4.66.1-py3-none-any.whl\nSaved ./kaggle/input/trl/typing_extensions-4.7.1-py3-none-any.whl\nSaved ./kaggle/input/trl/filelock-3.12.2-py3-none-any.whl\nSaved ./kaggle/input/trl/Jinja2-3.1.2-py3-none-any.whl\nSaved ./kaggle/input/trl/multiprocess-0.70.15-py310-none-any.whl\nSaved ./kaggle/input/trl/networkx-3.1-py3-none-any.whl\nSaved ./kaggle/input/trl/pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/sympy-1.12-py3-none-any.whl\nSaved ./kaggle/input/trl/xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/aiosignal-1.3.1-py3-none-any.whl\nSaved ./kaggle/input/trl/async_timeout-4.0.3-py3-none-any.whl\nSaved ./kaggle/input/trl/attrs-23.1.0-py3-none-any.whl\nSaved ./kaggle/input/trl/certifi-2023.7.22-py3-none-any.whl\nSaved ./kaggle/input/trl/charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/idna-3.4-py3-none-any.whl\nSaved ./kaggle/input/trl/MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/mpmath-1.3.0-py3-none-any.whl\nSaved ./kaggle/input/trl/multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/python_dateutil-2.8.2-py2.py3-none-any.whl\nSaved ./kaggle/input/trl/pytz-2023.3-py2.py3-none-any.whl\nSaved ./kaggle/input/trl/tzdata-2023.3-py2.py3-none-any.whl\nSaved ./kaggle/input/trl/urllib3-2.0.4-py3-none-any.whl\nSaved ./kaggle/input/trl/yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nSaved ./kaggle/input/trl/cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\nSaved ./kaggle/input/trl/fsspec-2023.6.0-py3-none-any.whl\nSaved ./kaggle/input/trl/lit-16.0.6.tar.gz\nSaved ./kaggle/input/trl/setuptools-68.1.2-py3-none-any.whl\nSaved ./kaggle/input/trl/wheel-0.41.2-py3-none-any.whl\nSaved ./kaggle/input/trl/six-1.16.0-py2.py3-none-any.whl\nSuccessfully downloaded trl numpy torch nvidia-cublas-cu11 nvidia-cuda-cupti-cu11 nvidia-cuda-nvrtc-cu11 nvidia-cuda-runtime-cu11 nvidia-cudnn-cu11 nvidia-cufft-cu11 nvidia-curand-cu11 nvidia-cusolver-cu11 nvidia-cusparse-cu11 nvidia-nccl-cu11 nvidia-nvtx-cu11 triton transformers accelerate datasets dill aiohttp huggingface-hub packaging pyarrow pyyaml regex requests safetensors tokenizers tqdm typing-extensions filelock jinja2 multiprocess networkx pandas psutil sympy xxhash aiosignal async-timeout attrs certifi charset-normalizer frozenlist idna MarkupSafe mpmath multidict python-dateutil pytz tzdata urllib3 yarl cmake fsspec lit setuptools wheel six\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls -d ./kaggle/input/*","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:14:31.101410Z","iopub.execute_input":"2023-08-22T11:14:31.101759Z","iopub.status.idle":"2023-08-22T11:14:32.135548Z","shell.execute_reply.started":"2023-08-22T11:14:31.101723Z","shell.execute_reply":"2023-08-22T11:14:32.134205Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"./kaggle/input/accelerate    ./kaggle/input/einops  ./kaggle/input/trl\n./kaggle/input/bitsandbytes  ./kaggle/input/peft\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nimport gc\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:14:32.141282Z","iopub.execute_input":"2023-08-22T11:14:32.142080Z","iopub.status.idle":"2023-08-22T11:14:40.362187Z","shell.execute_reply.started":"2023-08-22T11:14:32.142036Z","shell.execute_reply":"2023-08-22T11:14:40.361090Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    INPUT_ROOT = \"/kaggle/input/kaggle-llm-science-exam\"\n    MODEL_DIRS = [\n        \"/kaggle/input/dolly-v2-7b-8bit\",\n        \"/kaggle/input/falcon-7b-8bit\",\n    ]","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:14:40.363642Z","iopub.execute_input":"2023-08-22T11:14:40.364018Z","iopub.status.idle":"2023-08-22T11:14:40.371667Z","shell.execute_reply.started":"2023-08-22T11:14:40.363980Z","shell.execute_reply":"2023-08-22T11:14:40.370744Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv(f\"{CFG.INPUT_ROOT}/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:14:40.373524Z","iopub.execute_input":"2023-08-22T11:14:40.374995Z","iopub.status.idle":"2023-08-22T11:14:40.402728Z","shell.execute_reply.started":"2023-08-22T11:14:40.374949Z","shell.execute_reply":"2023-08-22T11:14:40.401857Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    print(\"Submit\")\n    infer_df = pd.read_csv(f\"{CFG.INPUT_ROOT}/test.csv\")\n    infer_df[\"answer\"] = \"A\"\nelse:\n    print(\"Test\")\n    infer_df = mainTrain_df\n    \nprint(trainExtra_df.shape, mainTrain_df.shape)\ninfer_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:14:40.404132Z","iopub.execute_input":"2023-08-22T11:14:40.404731Z","iopub.status.idle":"2023-08-22T11:14:40.421868Z","shell.execute_reply.started":"2023-08-22T11:14:40.404673Z","shell.execute_reply":"2023-08-22T11:14:40.420544Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Test\n(6000, 7) (200, 8)\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"   id                                             prompt  \\\n0   0  Which of the following statements accurately d...   \n1   1  Which of the following is an accurate definiti...   \n2   2  Which of the following statements accurately d...   \n3   3  What is the significance of regularization in ...   \n4   4  Which of the following statements accurately d...   \n\n                                                   A  \\\n0  MOND is a theory that reduces the observed mis...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol was reconstructed as a fe...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   B  \\\n0  MOND is a theory that increases the discrepanc...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol is a representation of th...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   C  \\\n0  MOND is a theory that explains the missing bar...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol is a representation of a ...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   D  \\\n0  MOND is a theory that reduces the discrepancy ...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol represents three interloc...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   E answer  \n0  MOND is a theory that eliminates the observed ...      D  \n1  Dynamic scaling refers to the evolution of sel...      A  \n2  The triskeles symbol is a representation of th...      A  \n3  Regularizing the mass-energy of an electron wi...      C  \n4  The angular spacing of features in the diffrac...      D  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>D</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class Perplexity(nn.Module):\n    def __init__(self, reduce: bool = True):\n        super().__init__()\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.reduce = reduce\n\n    def forward(self, logits, labels):\n        shift_logits = logits[..., :-1, :].contiguous()\n        shift_labels = labels[..., 1:].contiguous()\n\n        perplexity = []\n        for i in range(labels.shape[0]):\n            perplexity.append(self.loss_fn(shift_logits[i], shift_labels[i]))\n        perplexity = torch.stack(perplexity, dim=0)\n        #perplexity = torch.exp(perplexity)\n        if self.reduce:\n            perplexity = torch.mean(perplexity)\n        return perplexity.cpu().item()\n    \ndef precision_at_k(r, k):\n    \"\"\"Precision at k\"\"\"\n    assert k <= len(r)\n    assert k != 0\n    return sum(int(x) for x in r[:k]) / k\n\ndef MAP_at_3(predictions, true_items):\n    \"\"\"Score is mean average precision at 3\"\"\"\n    U = len(predictions)\n    map_at_3 = 0.0\n    for u in range(U):\n        user_preds = predictions[u]\n        user_true = true_items[u]\n        user_results = [1 if item == user_true else 0 for item in user_preds]\n        for k in range(min(len(user_preds), 3)):\n            map_at_3 += precision_at_k(user_results, k+1) * user_results[k]\n    return map_at_3 / U","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:14:40.423389Z","iopub.execute_input":"2023-08-22T11:14:40.425481Z","iopub.status.idle":"2023-08-22T11:14:40.437895Z","shell.execute_reply.started":"2023-08-22T11:14:40.425454Z","shell.execute_reply":"2023-08-22T11:14:40.436846Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"perplexity = Perplexity()\ncandidate = np.array([\"A\", \"B\", \"C\", \"D\", \"E\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:14:40.439402Z","iopub.execute_input":"2023-08-22T11:14:40.439835Z","iopub.status.idle":"2023-08-22T11:14:40.451362Z","shell.execute_reply.started":"2023-08-22T11:14:40.439798Z","shell.execute_reply":"2023-08-22T11:14:40.450269Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def infer(model_name, infer_df):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n\n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        torch_dtype=torch.bfloat16,\n#         load_in_8bit=True,\n        device_map=\"auto\",\n        trust_remote_code=True,\n    )\n    \n    predicts, scores = [], []\n    for _, row in tqdm(infer_df.iterrows(), total=len(infer_df)):\n        inp = row[\"prompt\"]\n        cands = [f\"Question: {inp}\\nAnswer: {row[c]}\" for c in candidate]\n\n        inputs = tokenizer(\n            cands,\n            return_tensors=\"pt\",\n            add_special_tokens=False,\n            padding=True, truncation=True\n        ).to(f\"cuda:{model.device.index}\")\n        with torch.no_grad():\n            output = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n        output = output.logits\n        labels = inputs[\"input_ids\"]\n        perp = [perplexity(output[i].unsqueeze(0), labels[i].unsqueeze(0)) for i in range(5)]\n        pred = candidate[np.argsort(perp)]\n        predicts.append(perp)\n\n        s = MAP_at_3([pred], [row[\"answer\"]])\n        scores.append(s)\n\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n    return predicts, scores","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:18:08.027740Z","iopub.execute_input":"2023-08-22T11:18:08.028123Z","iopub.status.idle":"2023-08-22T11:18:08.040011Z","shell.execute_reply.started":"2023-08-22T11:18:08.028092Z","shell.execute_reply":"2023-08-22T11:18:08.038773Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"!ls -d ./kaggle/input/*","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:14:40.466316Z","iopub.execute_input":"2023-08-22T11:14:40.467056Z","iopub.status.idle":"2023-08-22T11:14:41.518589Z","shell.execute_reply.started":"2023-08-22T11:14:40.467007Z","shell.execute_reply":"2023-08-22T11:14:41.517424Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"./kaggle/input/accelerate    ./kaggle/input/einops  ./kaggle/input/trl\n./kaggle/input/bitsandbytes  ./kaggle/input/peft\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install einops --no-index --find-links=file:./kaggle/input/einops\n!pip install bitsandbytes --no-index --find-links=file:./kaggle/input/bitsandbytes\n!pip install accelerate --no-index --find-links=file:./kaggle/input/accelerate","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:14:41.520466Z","iopub.execute_input":"2023-08-22T11:14:41.520975Z","iopub.status.idle":"2023-08-22T11:15:17.900071Z","shell.execute_reply.started":"2023-08-22T11:14:41.520931Z","shell.execute_reply":"2023-08-22T11:15:17.898830Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Looking in links: file:///./kaggle/input/einops\nProcessing ./kaggle/input/einops/einops-0.6.1-py3-none-any.whl\nInstalling collected packages: einops\nSuccessfully installed einops-0.6.1\nLooking in links: file:///./kaggle/input/bitsandbytes\nProcessing ./kaggle/input/bitsandbytes/bitsandbytes-0.41.1-py3-none-any.whl\nInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.41.1\nLooking in links: file:///./kaggle/input/accelerate\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install accelerate\n!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:15:17.902045Z","iopub.execute_input":"2023-08-22T11:15:17.902800Z","iopub.status.idle":"2023-08-22T11:15:40.626750Z","shell.execute_reply.started":"2023-08-22T11:15:17.902757Z","shell.execute_reply":"2023-08-22T11:15:40.625412Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.41.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"predicts = []\nimport pdb\n\nfor model_name in CFG.MODEL_DIRS:\n#     pdb.set_trace()\n    _predicts, _scores = infer(model_name, infer_df)\n    torch.cuda.empty_cache()\n    gc.collect()\n    print(model_name, np.mean(_scores))\n    predicts.append(_predicts)\n\npredicts = np.array(predicts)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T11:18:13.799127Z","iopub.execute_input":"2023-08-22T11:18:13.800277Z","iopub.status.idle":"2023-08-22T11:19:23.042749Z","shell.execute_reply.started":"2023-08-22T11:18:13.800232Z","shell.execute_reply":"2023-08-22T11:19:23.041425Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Detected the presence of a `quantization_config` attribute in the model's configuration but you don't have the correct `bitsandbytes` version to support int8 serialization. Please install the latest version of `bitsandbytes` with  `pip install --upgrade bitsandbytes`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m6\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mfor\u001b[0m model_name \u001b[95min\u001b[0m CFG.MODEL_DIRS:                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m#     pdb.set_trace()\u001b[0m                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 6 \u001b[2m│   \u001b[0m_predicts, _scores = infer(model_name, infer_df)                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   \u001b[0mtorch.cuda.empty_cache()                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0mgc.collect()                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(model_name, np.mean(_scores))                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92minfer\u001b[0m:\u001b[94m6\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m tokenizer.pad_token \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   │   \u001b[0mtokenizer.pad_token = tokenizer.eos_token                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 6 \u001b[2m│   \u001b[0mmodel = AutoModelForCausalLM.from_pretrained(                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_name,                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   │   \u001b[0mtorch_dtype=torch.bfloat16,                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m#         load_in_8bit=True,\u001b[0m                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mauto_factory.py\u001b[0m:\u001b[94m484\u001b[0m in          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m481 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m482 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mtype\u001b[0m(config) \u001b[95min\u001b[0m \u001b[96mcls\u001b[0m._model_mapping.keys():                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m483 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_class = _get_model_class(config, \u001b[96mcls\u001b[0m._model_mapping)                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m484 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m model_class.from_pretrained(                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m487 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m2881\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2878 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmismatched_keys,                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2879 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moffload_index,                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2880 \u001b[0m\u001b[2m│   │   │   │   \u001b[0merror_msgs,                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2881 \u001b[2m│   │   │   \u001b[0m) = \u001b[96mcls\u001b[0m._load_pretrained_model(                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2882 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel,                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2883 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mstate_dict,                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2884 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mloaded_state_dict_keys,  \u001b[2m# XXX: rename?\u001b[0m                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m2980\u001b[0m in                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92m_load_pretrained_model\u001b[0m                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2977 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2978 \u001b[0m\u001b[2m│   │   │   \u001b[0mis_safetensors = archive_file.endswith(\u001b[33m\"\u001b[0m\u001b[33m.safetensors\u001b[0m\u001b[33m\"\u001b[0m)                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2979 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m offload_folder \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m is_safetensors:                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2980 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2981 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mThe current `device_map` had weights offloaded to the disk. Please \u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2982 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m for them. Alternatively, make sure you have `safetensors` installe\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2983 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m offers the weights in this format.\u001b[0m\u001b[33m\"\u001b[0m                                 \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mValueError: \u001b[0mThe current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for \nthem. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in \nthis format.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> model_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> CFG.MODEL_DIRS:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 #     pdb.set_trace()</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 6 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>_predicts, _scores = infer(model_name, infer_df)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>torch.cuda.empty_cache()                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>gc.collect()                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(model_name, np.mean(_scores))                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">infer</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> tokenizer.pad_token <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>tokenizer.pad_token = tokenizer.eos_token                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 6 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model = AutoModelForCausalLM.from_pretrained(                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model_name,                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch_dtype=torch.bfloat16,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 #         load_in_8bit=True,</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">auto_factory.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">484</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">482 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(config) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapping.keys():                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">483 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>model_class = _get_model_class(config, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapping)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>484 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> model_class.from_pretrained(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">485 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">487 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2881</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2878 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>mismatched_keys,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2879 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>offload_index,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2880 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>error_msgs,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2881 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>) = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._load_pretrained_model(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2882 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>model,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2883 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>state_dict,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2884 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>loaded_state_dict_keys,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># XXX: rename?</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2980</span> in                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_pretrained_model</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2977 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2978 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>is_safetensors = archive_file.endswith(<span style=\"color: #808000; text-decoration-color: #808000\">\".safetensors\"</span>)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2979 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> offload_folder <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> is_safetensors:                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2980 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2981 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"The current `device_map` had weights offloaded to the disk. Please </span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2982 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" for them. Alternatively, make sure you have `safetensors` installe</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2983 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" offers the weights in this format.\"</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for \nthem. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in \nthis format.\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"if predicts.shape[0] == 1:\n    predicts_avg = predicts[0]\nelse:\n    predicts_avg = predicts.mean(0)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T10:57:26.729262Z","iopub.execute_input":"2023-08-22T10:57:26.729709Z","iopub.status.idle":"2023-08-22T10:57:27.185646Z","shell.execute_reply.started":"2023-08-22T10:57:26.729664Z","shell.execute_reply":"2023-08-22T10:57:27.183456Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpredicts\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      2\u001b[0m     predicts_avg \u001b[38;5;241m=\u001b[39m predicts[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mNameError\u001b[0m: name 'predicts' is not defined"],"ename":"NameError","evalue":"name 'predicts' is not defined","output_type":"error"}]},{"cell_type":"code","source":"sub_df[\"prediction\"] = [\" \".join(candidate[np.argsort(p)][:3]) for p in predicts_avg]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{},"execution_count":null,"outputs":[]}]}